{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import carla\n",
    "from detectors import torch_script_module\n",
    "from carla_control import carla_client\n",
    "from utils.mods.post_processing import mono_label_distance_tracker, multi_classes_assemble_tracker\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.init_client()\n",
    "client.start_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROOT_DIR': WindowsPath('D:/beamng_python_experiment'), 'LOCAL_RANK': 0, 'CLASS_NAMES': ['Car', 'Pedestrian', 'Cyclist'], 'DATA_CONFIG': {'POINT_CLOUD_RANGE': [0, -39.68, -3, 69.12, 39.68, 1], 'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding', 'used_feature_list': ['x', 'y', 'z', 'intensity'], 'src_feature_list': ['x', 'y', 'z', 'intensity']}, 'PREVIEW_CHANNEL': ['detector'], 'DATA_PROCESSOR': {'detector': [{'NAME': 'mask_points_by_range', 'POINT_CLOUD_RANGE': [0, -39.68, -3, 69.12, 39.68, 1]}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.16, 0.16, 4], 'MAX_POINTS_PER_VOXEL': 32, 'MAX_NUMBER_OF_VOXELS': {'train': 16000, 'test': 40000}}]}}, 'MODEL': {'NAME': 'PointPillar', 'POST_PROCESSING': {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7], 'SCORE_THRESH': 0.1, 'OUTPUT_RAW_SCORE': False, 'EVAL_METRIC': 'kitti', 'NMS_CONFIG': {'MULTI_CLASSES_NMS': False, 'NMS_TYPE': 'nms_gpu', 'NMS_THRESH': 0.01, 'NMS_PRE_MAXSIZE': 4096, 'NMS_POST_MAXSIZE': 500}}}}\n"
     ]
    }
   ],
   "source": [
    "client.debug_luanch_test()\n",
    "\n",
    "CFG_FILE = \".\\\\configs\\\\carla_predict_eval.yaml\"\n",
    "cfg = cfg_from_yaml_file(CFG_FILE, cfg)\n",
    "\n",
    "pcs_dataset = carla_point_cloud_dataset(dataset_cfg = cfg.DATA_CONFIG, logger=logger, lidar=client.lidar_t, class_names=cfg.CLASS_NAMES)\n",
    "object_tracker = multi_classes_assemble_tracker(num_classes=4, track_length=25, multi_head=True)\n",
    "model = torch.jit.load(\"./torch_scripts/point_pillar_model.pt\")\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carla_ticking(idx, data_dict): \n",
    "    before_time = time.perf_counter()\n",
    "    \n",
    "    client.carla_world.tick()\n",
    "    ego_vehicle_transform = client.vehicle.get_transform()\n",
    "    ego_vehicle_location = ego_vehicle_transform.location\n",
    "    ego_vehicle_rotation = ego_vehicle_transform.rotation\n",
    "    offset = carla.Vector3D(x=-8.5, y=0, z=3.5)\n",
    "    left_rear_location = ego_vehicle_location + ego_vehicle_rotation.get_right_vector() * offset.y + \\\n",
    "                                            ego_vehicle_rotation.get_forward_vector() * offset.x + \\\n",
    "                                            ego_vehicle_rotation.get_up_vector() * offset.z\n",
    "\n",
    "    spectator = client.carla_world.get_spectator()\n",
    "    spectator_transform = carla.Transform(left_rear_location, ego_vehicle_rotation)\n",
    "    spectator.set_transform(spectator_transform)\n",
    "        \n",
    "    after_time = time.perf_counter()\n",
    "    return after_time - before_time, None\n",
    "    \n",
    "def model_forwarding(idx, data_dict):\n",
    "    final_boxes, final_scores, final_labels = None, None, None\n",
    "    before_time = time.perf_counter()\n",
    "    \n",
    "    if data_dict[\"points\"] is not None:\n",
    "        pred_dicts, _ = model.forward(data_dict)\n",
    "        \n",
    "        cls_preds = pred_dicts[\"pred_scores\"]\n",
    "        box_preds = pred_dicts[\"pred_boxes\"]\n",
    "        label_preds = pred_dicts[\"pred_labels\"]\n",
    "\n",
    "        selected, selected_scores = class_agnostic_nms(\n",
    "                            box_scores=cls_preds, box_preds=box_preds,\n",
    "                            score_thresh=0.4\n",
    "                        )\n",
    "\n",
    "        final_scores = selected_scores\n",
    "        final_labels = label_preds[selected]\n",
    "        final_boxes = box_preds[selected]\n",
    "    after_time = time.perf_counter()\n",
    "    return after_time - before_time, data_dict, final_boxes, final_scores, final_labels\n",
    "\n",
    "def scene_rendering(idx, points, vis, final_boxes=None, final_scores=None, final_labels=None, gt_boxes=None):\n",
    "    before_time = time.perf_counter()\n",
    "    if points is not None:\n",
    "        draw_scenes(vis,\n",
    "                    points=points[:, 1:], ref_boxes=final_boxes,\n",
    "                    ref_scores=final_scores, ref_labels=final_labels, gt_boxes=gt_boxes, confidence=None\n",
    "                )\n",
    "    \n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    vis.clear_geometries()\n",
    "    after_time = time.perf_counter()\n",
    "    return after_time - before_time, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 16:59:22,328   INFO  Channel name: detector\n",
      "2023-11-29 16:59:22,329   INFO  Compute time: 0.006 + 0.058 + 0.062 + 0.000 == 0.127s\n",
      "2023-11-29 16:59:22,329   INFO  Target amount: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\beamng_python_experiment\\carla_predict_eval.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m data_dict \u001b[39m=\u001b[39m pcs_dataset\u001b[39m.\u001b[39mcollate_batch([data_dict])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m load_data_to_gpu(data_dict)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m forward_time, data_dict, final_boxes, final_scores, final_labels \u001b[39m=\u001b[39m model_forwarding(idx, data_dict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m render_time, _ \u001b[39m=\u001b[39m scene_rendering(idx, data_dict[\u001b[39m\"\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m\"\u001b[39m], vis, final_boxes, final_scores, final_labels, gt_boxes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m render_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "\u001b[1;32md:\\beamng_python_experiment\\carla_predict_eval.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m before_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m data_dict[\u001b[39m\"\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     pred_dicts, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(data_dict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     cls_preds \u001b[39m=\u001b[39m pred_dicts[\u001b[39m\"\u001b[39m\u001b[39mpred_scores\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/beamng_python_experiment/carla_predict_eval.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     box_preds \u001b[39m=\u001b[39m pred_dicts[\u001b[39m\"\u001b[39m\u001b[39mpred_boxes\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "visualizers = {}\n",
    "\n",
    "for channel_name in pcs_dataset.preview_channel:\n",
    "    visualizers[channel_name] = o3d.visualization.Visualizer()\n",
    "    visualizers[channel_name].create_window(window_name=channel_name)\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for idx, data_series in enumerate(pcs_dataset):\n",
    "            \n",
    "            ticking_time, _ = carla_ticking(idx, None)\n",
    "            \n",
    "            for channel_name, channel in data_series.items():\n",
    "                data_dict = data_series[channel_name]\n",
    "                vis = visualizers[channel_name]\n",
    "                \n",
    "                pre_time = data_dict[\"pre_time\"]\n",
    "                forward_time = 0.0\n",
    "                final_boxes, final_scores, final_labels = None, None, None\n",
    "                gt_boxes = data_dict.get(\"gt_boxes\", None)\n",
    "                \n",
    "                if data_dict[\"points\"] is not None:\n",
    "                    \n",
    "                    data_dict = pcs_dataset.collate_batch([data_dict])\n",
    "                    load_data_to_gpu(data_dict)\n",
    "\n",
    "                    forward_time, data_dict, final_boxes, final_scores, final_labels = model_forwarding(idx, data_dict)\n",
    "\n",
    "                    render_time, _ = scene_rendering(idx, data_dict[\"points\"], vis, final_boxes, final_scores, final_labels, gt_boxes)\n",
    "                    \n",
    "                    render_time = time.perf_counter()\n",
    "                    \n",
    "                    # if final_boxes is not None:\n",
    "                    #     object_tracker.updates_object(final_boxes[np.newaxis, :, :], final_labels[np.newaxis, :], final_scores[np.newaxis, :])\n",
    "\n",
    "                    # bounding_boxes, box_scores, box_labels, tracks = object_tracker.get_all_object()\n",
    "\n",
    "                    # draw_scenes(vis,\n",
    "                    #     points=data_dict['points'][:, 1:], ref_boxes=bounding_boxes,\n",
    "                    #     ref_scores=box_scores, ref_labels=box_labels, confidence=None, tracks=tracks\n",
    "                    # )\n",
    "                    # draw_scenes(vis,\n",
    "                    #     points=data_dict['points'][:, 1:], ref_boxes=None,\n",
    "                    #     ref_scores=None, ref_labels=None, confidence=None, tracks=None\n",
    "                    # )\n",
    "                    # vis.poll_events()\n",
    "                    # vis.update_renderer()\n",
    "                    # vis.clear_geometries()\n",
    "                    \n",
    "                    render_time = time.perf_counter() - render_time\n",
    "                    \n",
    "                    clear_output(wait=True)\n",
    "                    logger.info(f\"Channel name: {channel_name}\")\n",
    "                    logger.info(f\"Compute time: {pre_time:.3f} + {ticking_time:.3f} + {forward_time:.3f} + {render_time:.3f} == {pre_time + ticking_time + forward_time + render_time:.3f}s\")\n",
    "                    logger.info(f\"Target amount: {len(final_boxes if (final_boxes is not None) else [])}\")\n",
    "                    # logger.info(f\"current uuid:{object_tracker.get_last_uuid()}\")\n",
    "except EOFError:\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(124788, 4)\n",
    "(57300, 4)\n",
    "BoundingBox(Location(x=0.000000, y=0.000342, z=0.781807), Extent(x=1.852685, y=0.894339, z=0.774525), Rotation(pitch=0.000000, yaw=0.000000, roll=0.000000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "\t\"class_name\" : \"ViewTrajectory\",\n",
    "\t\"interval\" : 29,\n",
    "\t\"is_loop\" : false,\n",
    "\t\"trajectory\" : \n",
    "\t[\n",
    "\t\t{\n",
    "\t\t\t\"boundingbox_max\" : [ 69.118263244628906, 39.679920196533203, 16.415634155273438 ],\n",
    "\t\t\t\"boundingbox_min\" : [ -0.059999999999999998, -39.679874420166016, -6.9146575927734375 ],\n",
    "\t\t\t\"field_of_view\" : 60.0,\n",
    "\t\t\t\"front\" : [ -0.90307097537632919, 0.0017988087570628851, 0.42948757574567964 ],\n",
    "\t\t\t\"lookat\" : [ 34.529131622314452, 2.288818359375e-05, 4.75048828125 ],\n",
    "\t\t\t\"up\" : [ 0.42948904059539766, 0.0070563614983622357, 0.90304450154510629 ],\n",
    "\t\t\t\"zoom\" : 0.69999999999999996\n",
    "\t\t}\n",
    "\t],\n",
    "\t\"version_major\" : 1,\n",
    "\t\"version_minor\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_beampy_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
